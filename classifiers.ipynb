{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politician Sentiment Analysis - Classification\n",
    "\n",
    "Name:       Devin Patel  \n",
    "Class:      CS 588 - 01  \n",
    "Term:       FA 22  \n",
    "Project:    Determining party alignment based on 2016 Election tweets.  \n",
    "File Purpose: To gauge various classifier accuracies on selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SelectKBest       # ANOVA\n",
    "from sklearn.feature_selection import f_regression      # ANOVA\n",
    "\n",
    "from sklearn.model_selection import train_test_split    # Splits sample set into train/test sets\n",
    "from sklearn.model_selection import cross_val_score     # Used to evaluate classifier performance\n",
    "from sklearn.model_selection import StratifiedKFold     # Splits a matrix into K sections\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB              # Gaussian Naive Bayes\n",
    "from sklearn.svm import SVC                             # SVM\n",
    "from sklearn.neural_network import MLPClassifier        # CNN\n",
    "from sklearn.pipeline import Pipeline                   # For estimating classifier models\n",
    "\n",
    "import os                                               # For exporting figures\n",
    "\n",
    "\n",
    "# Paths and Constants\n",
    "twitter_data_path = r\"Data/TweetData.pkl\"\n",
    "RANDOM_STATE = 12\n",
    "KEPT_FEATURES = 2\n",
    "NORM_RANGE = (0, 1)\n",
    "N_SPLITS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports pyplot figure\n",
    "import os\n",
    "\n",
    "def exportFig(fname):\n",
    "    exportPath = r\"Figures/classifiers\"\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(exportPath): os.mkdir(exportPath)\n",
    "    except Exception:\n",
    "        print(\"Can't create a directory to store figures, so they will not be saved.\")\n",
    "        return\n",
    "    \n",
    "    exportPath = os.path.join(exportPath, fname)\n",
    "    \n",
    "    plt.savefig(exportPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function for a classifier\n",
    "def plot_learning_curve(classifier, X, y, tsizes=np.linspace(0.1, 0.5, 5), label=\"\", color='r', axes=None):\n",
    "    estimator = Pipeline([(\"scaler\", MinMaxScaler()), ('classifier', classifier)])\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(iris_x, iris_target, train_size=0.9, random_state=RANDOM_STATE, shuffle=True)\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_sizes = []\n",
    "    \n",
    "    # tsizes are the training sizes [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    for tsize in tsizes:\n",
    "        tsize_i = tsize*100\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=tsize, random_state=RANDOM_STATE, shuffle=True)\n",
    "        estimator.fit(x_train, y_train)\n",
    "        train_scores.append(estimator.score(x_train, y_train) * 100)\n",
    "        test_scores.append(estimator.score(x_test, y_test) * 100)\n",
    "        train_sizes.append(tsize_i)\n",
    "    \n",
    "    if axes is None:\n",
    "        _, axes = plt.subplot(2)\n",
    "    \n",
    "    #axes[0].errorbar(train_sizes, test_scores_mean, yerr=test_scores_std, capsize=5, color=color, label=label)\n",
    "    axes[0].plot(train_sizes, test_scores, \"o-\", color=color, label=label)\n",
    "    axes[1].plot(train_sizes, train_scores, \"o-\", color=color, label=label)\n",
    "    \n",
    "    print(f\"Training Accuracy of {label}: {train_scores[-1]}%\")\n",
    "    print(f\"Testing Accuracy of {label}: {test_scores[-1]}%\")\n",
    "    print()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from pkl file\n",
    "X_df = pd.read_pickle(twitter_data_path, compression='infer')\n",
    "\n",
    "# Separate ground truth from dataframe.\n",
    "party_gth_df = pd.DataFrame(X_df.pop('Party'))\n",
    "\n",
    "# Create class labels list for both ground truth dataframes\n",
    "party_gth_labels = [\"R\", \"D\"] # Based on preprocessing: 0 = Republican, 1 = Democrat\n",
    "\n",
    "# Create feature labels list\n",
    "feature_labels = X_df.columns.values.tolist()\n",
    "\n",
    "scaler_model = MinMaxScaler(feature_range=NORM_RANGE)\n",
    "scaler_model.fit(X_df)\n",
    "X = scaler_model.transform(X_df)\n",
    "X_df = pd.DataFrame(X, columns=feature_labels)\n",
    "\n",
    "X_subject_df = pd.concat([X_df['Likes'], X_df['Retweets'], X_df['Subjectivity']], axis=1)\n",
    "X_polar_df = pd.concat([X_df['Likes'], X_df['Retweets'], X_df['Polarity']], axis=1)\n",
    "\n",
    "X_subject = X_subject_df.to_numpy()\n",
    "X_polar = X_polar_df.to_numpy()\n",
    "\n",
    "# Data is ready\n",
    "print(f\"\\nShape of main dataframe: {X_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature selection here\n",
    "\n",
    "# PCA\n",
    "PCA_KEPT_COMPONENTS = KEPT_FEATURES # Max 4\n",
    "\n",
    "# Polarity removed\n",
    "pca = PCA(n_components=PCA_KEPT_COMPONENTS, random_state=RANDOM_STATE)\n",
    "X_r_subject = pca.fit_transform(X_subject)\n",
    "\n",
    "# Subjectivity removed\n",
    "X_r_polar = pca.fit_transform(X_polar)\n",
    "\n",
    "\n",
    "# LDA\n",
    "LDA_KEPT_COMPONENTS = 1 # Max 1 because 2 parties\n",
    "lda = LDA(n_components=LDA_KEPT_COMPONENTS)\n",
    "\n",
    "X_r2 = lda.fit_transform(X, party_gth_df[\"Party\"])\n",
    "X_r2_subject = lda.fit_transform(X_subject, party_gth_df['Party'])\n",
    "X_r2_polar = lda.fit_transform(X_polar, party_gth_df['Party'])\n",
    "\n",
    "\n",
    "# ANOVA\n",
    "ANOVA_KEPT_COMPONENTS = KEPT_FEATURES\n",
    "fs = SelectKBest(score_func=f_regression, k=ANOVA_KEPT_COMPONENTS)\n",
    "\n",
    "X_r3 = fs.fit_transform(X, party_gth_df['Party'])\n",
    "X_r3_subject = fs.fit_transform(X_subject, party_gth_df['Party'])\n",
    "X_r3_polar = fs.fit_transform(X_polar, party_gth_df['Party'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifiers\n",
    "CNN_LAYERS = (150, 125, 100, 75, 50)\n",
    "MAX_ITER = 500\n",
    "\n",
    "# Create a list of classifier models\n",
    "models = [('NB', GaussianNB()) # Naive Bayes\n",
    "          ,('SVM (RBF)', SVC(kernel='rbf', gamma='auto', random_state=RANDOM_STATE)) # SVM - RBF\n",
    "          ,('CNN (MLP)', MLPClassifier(hidden_layer_sizes=CNN_LAYERS, max_iter=MAX_ITER,\n",
    "                                       activation='relu', solver='adam', random_state=RANDOM_STATE)) # CNN\n",
    "          ]\n",
    "\n",
    "MAX_TRAIN_SIZE = 0.5\n",
    "\n",
    "classifier_labels = {\"Gaussian Naive Bayes\": (models[0][1], \"green\")\n",
    "                    ,\"SVM - RBF\": (models[1][1], \"blue\")\n",
    "                    ,\"CNN - MLP\": (models[2][1] ,\"red\")\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each classifier's accuracy on 30% train size (by default)\n",
    "def classifier_accuracy_comparison(X, y, n_splits=N_SPLITS, title=\"Default Title\", outfile=r\"Default.png\"):\n",
    "    # Evaluate each model\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=n_splits, random_state=RANDOM_STATE, shuffle=True)\n",
    "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print(f\"{name}: {cv_results.mean()*100}% ({cv_results.std()})\")\n",
    "\n",
    "    # Compare Algorithms\n",
    "    plt.figure()\n",
    "    plt.boxplot(results, labels=names)\n",
    "    plt.title(title)\n",
    "\n",
    "    exportFig(outfile)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests accuracy of classifiers on PCA\n",
    "# With subjectivity\n",
    "classifier_accuracy_comparison(X_r_subject, party_gth_df['Party'], n_splits=N_SPLITS,\n",
    "                               title='Classifier Accuracy Comparison\\nWithout Polarity',\n",
    "                               outfile=r\"Classifier-Comparison-Subject-PCA.png\")\n",
    "\n",
    "# With polarity\n",
    "classifier_accuracy_comparison(X_r_polar, party_gth_df['Party'], n_splits=N_SPLITS,\n",
    "                               title='Classifier Accuracy Comparison\\nWithout Subjectivity',\n",
    "                               outfile=r\"Classifier-Comparison-Polar-PCA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates accuracy plots for subjectivity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r_subject, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With PCA Without Polarity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With PCA Without Polarity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"Classifier-Subject-PCA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for polarity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r_polar, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With PCA Without Subjectivity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With PCA Without Subjectivity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"Classifier-Polar-PCA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests accuracy of classifiers on LDA\n",
    "# With subjectivity\n",
    "classifier_accuracy_comparison(X_r2_subject, party_gth_df['Party'], n_splits=N_SPLITS,\n",
    "                               title='Classifier Accuracy Comparison\\nWithout Polarity',\n",
    "                               outfile=r\"Classifier-Comparison-Subject-LDA.png\")\n",
    "\n",
    "# With polarity\n",
    "classifier_accuracy_comparison(X_r2_polar, party_gth_df['Party'], n_splits=N_SPLITS,\n",
    "                               title='Classifier Accuracy Comparison\\nWithout Subjectivity',\n",
    "                               outfile=r\"Classifier-Comparison-Polar-LDA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for subjectivity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r2_subject, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With LDA Without Polarity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With LDA Without Polarity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"Classifier-Subject-LDA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for polarity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r2_polar, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With LDA Without Subjectivity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With LDA Without Subjectivity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"Classifier-Polar-LDA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests accuracy of classifiers on ANOVA\n",
    "# With subjectivity\n",
    "classifier_accuracy_comparison(X_r3_subject, party_gth_df['Party'], n_splits=N_SPLITS,\n",
    "                               title='Classifier Accuracy Comparison\\nWithout Polarity',\n",
    "                               outfile=r\"Classifier-Comparison-Subject-ANOVA.png\")\n",
    "\n",
    "# With polarity\n",
    "classifier_accuracy_comparison(X_r3_polar, party_gth_df['Party'], n_splits=N_SPLITS,\n",
    "                               title='Classifier Accuracy Comparison\\nWithout Subjectivity',\n",
    "                               outfile=r\"Classifier-Comparison-Polar-ANOVA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for subjectivity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r3_subject, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With ANOVA Without Polarity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With ANOVA Without Polarity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"Classifier-Subject-ANOVA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for polarity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r3_polar, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With ANOVA Without Subjectivity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With ANOVA Without Subjectivity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"Classifier-Polar-ANOVA.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('TermProjectEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7617d9f353d0ac9f570adc94844bb2aa03fcb9b0dde070c514e1bea26a08c65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
