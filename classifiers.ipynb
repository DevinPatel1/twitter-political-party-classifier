{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politician Sentiment Analysis - Classification\n",
    "\n",
    "Name:       Devin Patel  \n",
    "Class:      CS 588 - 01  \n",
    "Term:       FA 22  \n",
    "Project:    Determining party alignment based on 2016 Election tweets.  \n",
    "File Purpose: To gauge various classifier accuracies on selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SelectKBest       # ANOVA\n",
    "from sklearn.feature_selection import f_regression      # ANOVA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split    # Splits sample set into train/test sets\n",
    "from sklearn.model_selection import cross_val_score     # Used to evaluate classifier performance\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold     # Splits a matrix into K sections\n",
    "from sklearn.naive_bayes import GaussianNB              # Gaussian Naive Bayes\n",
    "from sklearn.svm import SVC                             # SVM\n",
    "from sklearn.neural_network import MLPClassifier        # CNN\n",
    "from sklearn.pipeline import Pipeline                   # For estimating classifier models\n",
    "from sklearn.metrics import ConfusionMatrixDisplay      # For gauging classifier model accuracy\n",
    "\n",
    "import os                                               # For exporting figures\n",
    "import dataframe_image as dfi\n",
    "import json\n",
    "\n",
    "\n",
    "# Paths and Constants\n",
    "twitter_data_path = r\"Data/TweetData.pkl\"\n",
    "RANDOM_STATE = 12\n",
    "KEPT_FEATURES = 2\n",
    "NORM_RANGE = (0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports pyplot figure\n",
    "import os\n",
    "\n",
    "def exportFig(fname):\n",
    "    exportPath = \"Figures/dimension_reduction\"\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(exportPath): os.mkdir(exportPath)\n",
    "    except Exception:\n",
    "        print(\"Can't create a directory to store figures, so they will not be saved.\")\n",
    "        return\n",
    "    \n",
    "    exportPath = os.path.join(exportPath, fname)\n",
    "    \n",
    "    plt.savefig(exportPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function for a classifier\n",
    "def plot_learning_curve(classifier, X, y, tsizes=np.linspace(0.1, 0.5, 5), label=\"\", color='r', axes=None):\n",
    "    estimator = Pipeline([(\"scaler\", MinMaxScaler()), ('classifier', classifier)])\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(iris_x, iris_target, train_size=0.9, random_state=RANDOM_STATE, shuffle=True)\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_sizes = []\n",
    "    \n",
    "    # tsizes are the training sizes [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    for tsize in tsizes:\n",
    "        tsize_i = tsize*100\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=tsize, random_state=RANDOM_STATE, shuffle=True)\n",
    "        estimator.fit(x_train, y_train)\n",
    "        train_scores.append(estimator.score(x_train, y_train) * 100)\n",
    "        test_scores.append(estimator.score(x_test, y_test) * 100)\n",
    "        train_sizes.append(tsize_i)\n",
    "    \n",
    "    if axes is None:\n",
    "        _, axes = plt.subplot(2)\n",
    "    \n",
    "    #axes[0].errorbar(train_sizes, test_scores_mean, yerr=test_scores_std, capsize=5, color=color, label=label)\n",
    "    axes[0].plot(train_sizes, test_scores, \"o-\", color=color, label=label)\n",
    "    axes[1].plot(train_sizes, train_scores, \"o-\", color=color, label=label)\n",
    "    \n",
    "    print(f\"Training Accuracy of {label}: {train_scores[-1]}%\")\n",
    "    print(f\"Testing Accuracy of {label}: {test_scores[-1]}%\")\n",
    "    print()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of main dataframe: (65952, 4)\n"
     ]
    }
   ],
   "source": [
    "# Loading data from pkl file\n",
    "X_df = pd.read_pickle(twitter_data_path, compression='infer')\n",
    "\n",
    "# Separate ground truth from dataframe.\n",
    "party_gth_df = pd.DataFrame(X_df.pop('Party'))\n",
    "\n",
    "# Create class labels list for both ground truth dataframes\n",
    "party_gth_labels = [\"R\", \"D\"] # Based on preprocessing: 0 = Republican, 1 = Democrat\n",
    "\n",
    "# Create feature labels list\n",
    "feature_labels = X_df.columns.values.tolist()\n",
    "\n",
    "scaler_model = MinMaxScaler(feature_range=NORM_RANGE)\n",
    "scaler_model.fit(X_df)\n",
    "X = scaler_model.transform(X_df)\n",
    "X_df = pd.DataFrame(X, columns=feature_labels)\n",
    "\n",
    "X_subject_df = pd.concat([X_df['Likes'], X_df['Retweets'], X_df['Subjectivity']], axis=1)\n",
    "X_polar_df = pd.concat([X_df['Likes'], X_df['Retweets'], X_df['Polarity']], axis=1)\n",
    "\n",
    "X_subject = X_subject_df.to_numpy()\n",
    "X_polar = X_polar_df.to_numpy()\n",
    "\n",
    "# Data is ready\n",
    "print(f\"\\nShape of main dataframe: {X_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature selection here\n",
    "\n",
    "# PCA\n",
    "PCA_KEPT_COMPONENTS = KEPT_FEATURES # Max 4\n",
    "\n",
    "# Polarity removed\n",
    "pca = PCA(n_components=PCA_KEPT_COMPONENTS, random_state=RANDOM_STATE)\n",
    "X_r_subject = pca.fit_transform(X_subject)\n",
    "\n",
    "# Subjectivity removed\n",
    "X_r_polar = pca.fit_transform(X_polar)\n",
    "\n",
    "\n",
    "# LDA\n",
    "LDA_KEPT_COMPONENTS = 1 # Max 1 because 2 parties\n",
    "lda = LDA(n_components=LDA_KEPT_COMPONENTS)\n",
    "\n",
    "X_r2 = lda.fit_transform(X, party_gth_df[\"Party\"])\n",
    "X_r2_subject = lda.fit_transform(X_subject, party_gth_df['Party'])\n",
    "X_r2_polar = lda.fit_transform(X_polar, party_gth_df['Party'])\n",
    "\n",
    "\n",
    "# ANOVA\n",
    "ANOVA_KEPT_COMPONENTS = KEPT_FEATURES\n",
    "fs = SelectKBest(score_func=f_regression, k=ANOVA_KEPT_COMPONENTS)\n",
    "\n",
    "X_r3 = fs.fit_transform(X, party_gth_df['Party'])\n",
    "X_r3_subject = fs.fit_transform(X_subject, party_gth_df['Party'])\n",
    "X_r3_polar = fs.fit_transform(X_polar, party_gth_df['Party'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifiers\n",
    "CNN_LAYERS = (150, 125, 100, 75, 50)\n",
    "MAX_ITER = 500\n",
    "\n",
    "# Create a list of classifier models\n",
    "models = [('NB', GaussianNB()) # Naive Bayes\n",
    "          ,('SVM (RBF)', SVC(kernel='rbf', gamma='auto', random_state=RANDOM_STATE)) # SVM - RBF\n",
    "          ,('CNN (MLP)', MLPClassifier(hidden_layer_sizes=CNN_LAYERS, max_iter=MAX_ITER,\n",
    "                                       activation='relu', solver='adam', random_state=RANDOM_STATE)) # CNN\n",
    "          ]\n",
    "\n",
    "MAX_TRAIN_SIZE = 0.5\n",
    "\n",
    "classifier_labels = {\"Gaussian Naive Bayes\": (models[0][1], \"green\")\n",
    "                    ,\"SVM - RBF\": (models[1][1], \"blue\")\n",
    "                    ,\"CNN - MLP\": (models[2][1] ,\"red\")\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Gaussian Naive Bayes: 53.5207423580786%\n",
      "Testing Accuracy of Gaussian Naive Bayes: 53.00824842309558%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates plots for subjectivity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r_subject, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With PCA Without Polarity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With PCA Without Polarity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"classifiers/Classifier-Subject-PCA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for polarity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r_polar, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With PCA Without Subjectivity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With PCA Without Subjectivity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"classifiers/Classifier-Polar-PCA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for subjectivity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r2_subject, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With LDA Without Polarity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With LDA Without Polarity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"classifiers/Classifier-Subject-LDA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for polarity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r2_polar, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With LDA Without Subjectivity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With LDA Without Subjectivity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"classifiers/Classifier-Polar-LDA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for subjectivity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r3_subject, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With ANOVA Without Polarity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With ANOVA Without Polarity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"classifiers/Classifier-Subject-ANOVA.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots for polarity\n",
    "_, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for label in classifier_labels:\n",
    "    classifier = classifier_labels[label][0]\n",
    "    color = classifier_labels[label][1]\n",
    "    plot_learning_curve(classifier, X_r3_polar, party_gth_df['Party'].astype('int'), tsizes=np.linspace(0.1, MAX_TRAIN_SIZE, int(MAX_TRAIN_SIZE*10)), label=label, color=color, axes=axes)\n",
    "\n",
    "axes[0].set_xlabel(r\"% Training Data\")\n",
    "axes[0].set_ylabel(\"Overall Classification Accuracy\")\n",
    "axes[0].set_title(f\"Cross-validation Accuracy -\\nReduced With ANOVA Without Subjectivity\", fontweight=10)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel(r\"% Training Data\")\n",
    "axes[1].set_ylabel(\"Training/Recall Accuracy\")\n",
    "axes[1].set_title(f\"Training Accuracy -\\nReduced With ANOVA Without Subjectivity\", fontweight=10)\n",
    "axes[1].legend()\n",
    "\n",
    "exportFig(r\"classifiers/Classifier-Polar-ANOVA.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('TermProjectEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e72866615fe58db29ecb495c2e0a5a245101998666c55885bf45c1dc41d765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
